{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pygame\n",
    "\n",
    "def check_winner(board, player):\n",
    "    # Проверка горизонтальных линий\n",
    "    for row in board:\n",
    "        if all(cell == player for cell in row):\n",
    "            return True\n",
    "\n",
    "    # Проверка вертикальных линий\n",
    "    for col in range(len(board[0])):\n",
    "        if all(row[col] == player for row in board):\n",
    "            return True\n",
    "\n",
    "    # Проверка диагоналей (основная и побочная)\n",
    "    if all(board[i][i] == player for i in range(len(board))) or \\\n",
    "       all(board[i][len(board) - i - 1] == player for i in range(len(board))):\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "class ticTacToe():\n",
    "    def __init__(self):\n",
    "        self.positions = [(0, 0), (0, 1), (0, 2), (1, 0), (1, 1), (1, 2), (2, 0), (2, 1), (2, 2)]\n",
    "\n",
    "        self.input_size = 9\n",
    "        self.output_size = 9\n",
    "\n",
    "    def reset(self):\n",
    "\n",
    "        self.num_steps = 0\n",
    "        self.state =   [[0,0,0],\n",
    "                        [0,0,0],\n",
    "                        [0,0,0]]\n",
    "        \n",
    "        state_for_robots = scaler.transform(self.state)\n",
    "\n",
    "        # return state_for_robots.flatten()\n",
    "        return np.array(self.state).flatten()\n",
    "\n",
    "    def step1(self, action):   \n",
    "        done = False\n",
    "        reward = 0\n",
    "        self.num_steps += 1\n",
    "\n",
    "        row, col = self.positions[action]\n",
    "\n",
    "        if self.state[row][col] == 0:\n",
    "            self.state[row][col] = 1\n",
    "        else:\n",
    "            done = True\n",
    "            reward = -5 \n",
    "\n",
    "        if not(np.isin(0, np.array(self.state))):\n",
    "            done = True\n",
    "\n",
    "        if check_winner(self.state, 1):\n",
    "            done = True\n",
    "            reward = 1\n",
    "        \n",
    "        state_for_robots = scaler.transform(self.state)\n",
    "\n",
    "\n",
    "        \n",
    "        # return state_for_robots.flatten(), reward, done\n",
    "        return np.array(self.state).flatten(), reward, done\n",
    "    \n",
    "    def step2(self, action):   \n",
    "        done = False\n",
    "        reward = 0\n",
    "        self.num_steps += 1\n",
    "\n",
    "        row, col = self.positions[action]\n",
    "\n",
    "        if self.state[row][col] == 0:\n",
    "            self.state[row][col] = -1\n",
    "        else:\n",
    "            done = True\n",
    "            reward = -5  \n",
    "\n",
    "        if not(np.isin(0, np.array(self.state))):\n",
    "            done = True\n",
    "            \n",
    "\n",
    "        if check_winner(self.state,-1):\n",
    "            done = True\n",
    "            reward = 1\n",
    "        \n",
    "\n",
    "        state_for_robots = scaler.transform(self.state)\n",
    "        \n",
    "        # return state_for_robots.flatten(), reward, done\n",
    "        return np.array(self.state).flatten(), reward, done\n",
    "\n",
    "\n",
    "    def render(self):\n",
    "        for i in range(len(self.state)):\n",
    "            print(self.state[i])\n",
    "\n",
    "    \n",
    "# Функция для сэмплирования действия на основе политики\n",
    "def select_action(net, state):\n",
    "    state = torch.tensor(state, dtype=torch.float32)\n",
    "    action_probs = net(state)\n",
    "    action = np.random.choice(len(action_probs.detach().numpy()), p=action_probs.detach().numpy())\n",
    "    return action        \n",
    "\n",
    "def test1(net, num_episodes=10):\n",
    "    for episode in range(num_episodes):\n",
    "        print('RESTARTING')\n",
    "        state = env.reset()\n",
    "        step = 0\n",
    "        while True:\n",
    "            env.render()\n",
    "\n",
    "            if step%2 == 0:\n",
    "                action = int(input())\n",
    "                next_state, reward, done = env.step1(action)\n",
    "                if reward < 0:\n",
    "                    print('Ты ошибся')\n",
    "                elif reward > 0:\n",
    "                    print('Ты выиграл')\n",
    "            else:\n",
    "                action = select_action(net, state)\n",
    "                next_state, reward, done = env.step2(action)\n",
    "                if reward < 0:\n",
    "                    print('Робот ошибся')\n",
    "                elif reward > 0:\n",
    "                    print('Робот выиграл')\n",
    "                \n",
    "            step += 1\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "            state = next_state\n",
    "\n",
    "def test2(net, num_episodes=10):\n",
    "    for episode in range(num_episodes):\n",
    "        print('RESTARTING')\n",
    "        state = env.reset()\n",
    "        step = 0\n",
    "        while True:\n",
    "\n",
    "            env.render()\n",
    "\n",
    "            if step%2 == 0:\n",
    "                action = select_action(net, state)\n",
    "                next_state, reward, done = env.step1(action)\n",
    "                if reward < 0:\n",
    "                    print('Робот ошибся')\n",
    "                elif reward > 0:\n",
    "                    print('Робот выиграл')\n",
    "            else:\n",
    "\n",
    "                action = int(input())\n",
    "                while True:\n",
    "                    if action == 0 or action == 1 or action == 2 or action == 3 or action == 4 or action == 5 or action == 6 or action == 7 or action == 8:\n",
    "                        next_state, reward, done = env.step2(action)\n",
    "                        break\n",
    "                    else:\n",
    "                        print('неправильное действие')\n",
    "                        action = int(input())\n",
    "\n",
    "                if reward < 0:\n",
    "                    print('Ты ошибся')\n",
    "                elif reward > 0:\n",
    "                    print('Ты выиграл')\n",
    "            step += 1\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "            state = next_state\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "env = ticTacToe()\n",
    "\n",
    "scaler.fit([[1,-1,0], [0,-1,0], [1,0,-1]])\n",
    "\n",
    "episodes = 1000000000\n",
    "\n",
    "#Здесь будет лоад\n",
    "\n",
    "test1(net2)\n",
    "\n",
    "test2(net1)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
